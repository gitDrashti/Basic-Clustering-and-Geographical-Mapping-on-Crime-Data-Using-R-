#Cleanup
gc()
#Build submission.
submit <- data.frame(predict(model,test, proba = TRUE)$probabilities[, levels(target)])
#```
#```{r echo=TRUE, message=FALSE, warning=FALSE}
#```
train <- read.csv("C:/Users/Pinank/Desktop/train.csv")
View(train)
library (dplyr)
library(ggplot2)
library(data.table)
library(reshape2)
library(readr)
library(lubridate)
library(RgoogleMaps)
train<- filter(train,Category != "OTHER OFFENSES", Category != "NON-CRIMINAL", Category != "WARRANTS")
train$Year <- year(ymd_hms(train$Dates))
crimes_per_year <- table(train$Category,train$Year)
crimes_per_year <- melt(crimes_per_year)
names(crimes_per_year) <- c("Category","Year","Count")
crimes_per_year=data.table(crimes_per_year)
#according to https://en.wikipedia.org/wiki/White-collar_crime#Blue-collar_crime
white_crime=c("FRAUD", "FORGERY/COUNTERFEITING", "BAD CHECKS" , "EXTORTION", "EMBEZZLEMENT", "SUSPICIOUS OCC",
"BRIBERY")
blue_crime=c("VANDALISM", "LARCENY/THEFT", "STOLEN PROPERTY", "ROBBERY", "DRIVING UNDER THE INFLUENCE",
"DISORDERLY CONDUCT", "LIQUOR LAWS", "VEHICLE THEFT", "ASSAULT", "KIDNAPPING", "TRESPASS",
"ARSON", "RECOVERED VEHICLE")
other_crime=c("MISSING PERSON", "RUNAWAY", "FAMILY OFFENSES", "SEX OFFENSES NON FORCIBLE",
"PORNOGRAPHY/OBSCENE MAT", "WEAPON LAWS", "DRUNKENNESS", "SUICIDE", "TREA",
"DRUG/NARCOTIC", "SEX OFFENSES FORCIBLE",  "LOITERING")
"%ni%" <- Negate("%in%")
crimes_per_year[, Collar := character(nrow(crimes_per_year))]
crimes_per_year[Category %in% blue_crime, Collar := "BLUE COLLAR"]
crimes_per_year[Category %in% white_crime, Collar := "WHITE COLLAR"]
crimes_per_year[Category %ni% blue_crime & Category %ni% white_crime, Collar := "OTHER"]
g <- ggplot(crimes_per_year,aes(x=Year, y=Count,fill = Collar)) +
geom_bar(stat = "identity")+
coord_flip() +
facet_grid(.~Collar) +
labs(title="White-Collar vs Blue-Collar Crimes in SF")
ggsave("White_Collar_vs_Blue_Collar.png", g, width=14, height=10, units="in")
rm(crimes_per_year)
rm(g)
train=data.table(train)
train[, Collar := character(nrow(train))]
train[Category %in% blue_crime, Collar := "BLUE COLLAR"]
train[Category %in% white_crime, Collar := "WHITE COLLAR"]
train[Category %ni% blue_crime & Category %ni% white_crime, Collar := "OTHER"]
train <- filter(train, Collar != "OTHER")
library(ggmap)
mapImageData3 <- get_map(location = c(lon = -122.431297, lat =  37.773972),
color = "color",
source = "google",
maptype = "roadmap",
zoom = 16)
ggmap(mapImageData3,
extent = "device",
ylab = "Latitude",
xlab = "Longitude")
p_df <- train[train$Collar=="WHITE COLLAR",]
p_df <- data.frame(X=p_df$X, Y=p_df$Y)
#data is too large for pam, so let's use clara instead
library(cluster)
p_clusters<- clara(p_df,3)
p_clusters <- as.data.frame(p_clusters$medoids)
p <- ggmap(mapImageData3)+
geom_point(data=train[train$Collar=="WHITE COLLAR"], aes(x=X, y=Y, color=factor(Collar)), alpha=0.05) +
guides(colour = guide_legend(override.aes = list(alpha=1.0, size=6.0),
title="Crime Type")) +
scale_colour_brewer(type="qual",palette="Paired") +
ggtitle("White-Collar crimes in SF") +
scale_color_manual(values=c("#FF0000", "#0000FF"))+
theme_light(base_size=20) +
theme(axis.line=element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank(),
axis.ticks=element_blank(),
axis.title.x=element_blank(),
axis.title.y=element_blank())
p <- p + geom_point(data=p_clusters, aes(x=X, y=Y, color="center"), alpha=0.3, size=30)
ggsave("White_Collar_Crime_Map.png", p, width=10, height=8, units="in")
rm(p, p_clusters, p_df)
b_df <- train[train$Collar=="BLUE COLLAR",]
b_df <- data.frame(X=b_df$X, Y=b_df$Y)
#data is too large for pam, so let's use clara instead
b_clusters <- clara(b_df, 3)
b_clusters <- as.data.frame(b_clusters$medoids)
b <- ggmap(mapImageData3)+
geom_point(data=train[train$Collar=="BLUE COLLAR"], aes(x=X, y=Y, color=factor(Collar)), alpha=0.05) +
guides(colour = guide_legend(override.aes = list(alpha=1.0, size=6.0),
title="Crime Type")) +
scale_colour_brewer(type="qual",palette="Paired") +
ggtitle("Blue-Collar crimes in SF") +
scale_color_manual(values=c("#0000FF", "#FF0000"))+
theme_light(base_size=20) +
theme(axis.line=element_blank(),
axis.text.x=element_blank(),
axis.text.y=element_blank(),
axis.ticks=element_blank(),
axis.title.x=element_blank(),
axis.title.y=element_blank())
b <- b + geom_point(data=b_clusters, aes(x=X, y=Y, color="center"), alpha=0.3, size=30)
ggsave("Blue_Collar_Crime_Map.png", b, width=10, height=8, units="in")
rm(b, b_clusters, b_df)
rm(train)
---
title: "San-Francisco Crime Analysis: Exploratory Analysis and Classification"
author: "Drashti Patel"
---
### Introduction
#Here I analyzed the crime incidents in the city of San Francisco.
#I performed exploratory analysis and identified variables that affect crime category.
#These are,
#- Year
#- Month
#- Day of week
#- Hour of day
#- Location
-
# Next, I used R's Liblinear package to implement a L2-regularized logistic regression model to predict probability of each crime.
#For the final model, I used all the data for training. However, to select features for training,
#I had split data into test and validation sets.
#This scheme got me in early 400s, with a log loss about 2.6.
## Loading data and map
#```{r echo=FALSE, message=FALSE, warning=FALSE}
library(ggmap)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(caret)
library(e1071)
library(dbscan)
library(MASS)
library(ggExtra)
library(LiblineaR)
library(readr)
#```
### Additional variables:
#I created 8 additional variables,
#1. Years: Year in which crime occured
#2. Month: Month in which crime occured 1-January, 2-February, . . . , 12- December.
#3. DayOfMonth: 1 to 31 indicating date
#4. Hour: Hour of the day
#5. YearsMo: Years-month combination to investigate time-trend
#6. HourZn: Coarser descritication of hours in a day.
#7. weekday: Factor variable indicating if a day falls on weekend or on weekday,
#8. AddressType: Some addresses were entered as intersections and others as full addresses so I made this variable from address.
#```{r echo=FALSE, message=FALSE, warning=FALSE, loading_data}
# Loading data and map:
data_train <-
read_csv(file="C:/Users/Pinank/Desktop/train.csv")
data_test <-
read_csv(file="C:/Users/Pinank/Desktop/test.csv")
#map <-
#readRDS("../input/sf_map_copyright_openstreetmap_contributors.rds")
ggmap(map, extent='device')
geom_point(data=sample_n(data_train,10000), aes(x=X, y=Y),
alpha = 1/10,color = "red")+
scale_colour_brewer(type="qual")
#``
#```{r echo=FALSE, message=FALSE, warning=FALSE, functions}
# functions to draw map of crime on SFO'smap.
map_crime <- function(crime_df, crime) {
filtered <- filter(crime_df, Category %in% crime)
plot <- ggmap(map, extent='device') +
geom_point(data=filtered,
aes(x=X, y=Y, color=Category), alpha=0.1)
return(plot)
}
plot_crime_day <- function(crime_df, crime,wday) {
filtered <- filter(crime_df, Category %in% crime )
filtered <- summarise(group_by(filtered, Month,Years),
count = n())
print(filtered)
plot <- ggplot(data = filtered,
aes(x = Month,y = count,color = Years)) +
geom_point()
return(plot)
}
# functions to make variables from date info.
make_vars_date <- function(crime_df) {
crime_df$Years = strftime(strptime(crime_df$Dates,
"%Y-%m-%d %H:%M:%S"),"%Y")
crime_df$Month = strftime(strptime(crime_df$Dates,
"%Y-%m-%d %H:%M:%S"),"%m")
crime_df$DayOfMonth = strftime(strptime(crime_df$Dates,
"%Y-%m-%d %H:%M:%S"),"%d")
crime_df$Hour = strftime(strptime(crime_df$Dates,
"%Y-%m-%d %H:%M:%S"),"%H")
crime_df$YearsMo = paste( crime_df$Years, crime_df$Month ,
sep = "-" )
crime_df$DayOfWeek = factor(crime_df$DayOfWeek,
levels=c("Monday","Tuesday",
"Wednesday","Thursday",
"Friday","Saturday","Sunday"),
ordered=TRUE)
crime_df$weekday = "Weekday"
crime_df$weekday[crime_df$DayOfWeek== "Saturday" |
crime_df$DayOfWeek== "Sunday" |
crime_df$DayOfWeek== "Friday" ] = "Weekend"
addr_spl = strsplit(as.character(crime_df$Address),"/")
crime_df$AddressType = "Non-Intersection"
ind_l = vector()
ind_inxn = sapply(1:dim(crime_df)[1],
function(x) length(addr_spl[[x]]) == 2)
crime_df$AddressType[ ind_inxn ]="Intersection"
return(crime_df)
}
# functions to make contour maps
map_contours <- function(data_trunc, alp) {
p1 = ggmap(map, extent='device') +
geom_point(data=data_trunc, aes(x=X, y=Y), alpha= alp) +
stat_density2d(aes(x = X, y = Y,
fill = ..level.., alpha = ..level..),
size = 0.1, data = data_trunc, n=100,
geom = "polygon") +
theme(legend.position="none")
return(p1)
}
plot_marginals <- function(data_trunc) {
p2 = ggplot(data=data_trunc, aes(x=X, y=Y), alpha=0.1)+
geom_point()
p2 = ggMarginal(p2 + theme_gray(), type = "histogram",
fill = "steelblue", col = "darkblue")
return(p2)
}
#```{r echo=FALSE, message=FALSE, warning=FALSE, functions}
# Making additional variables.
data_train = make_vars_date(data_train)
data_test = make_vars_date(data_test)
data_train_ss <- sample_n(data_train,10000)
head(data_train)
## Types of crime.
#I next draw a bar plot to show number of crimes in each category.
#Bar plots indicate that the top crime categroy is Larceny/Theft.
#Further, top 20 crime types account for 97% of the crimes.
# Types of crimes.
data_plot = data_train %>%
group_by(Category) %>%
summarise(count = n()) %>%
transform(Category = reorder(Category,-count))
ggplot(data_plot) +
geom_bar(aes(x=Category, y=count,
color = Category, fill = Category),
stat="identity")+
coord_flip()+
theme(legend.position="None")+
ggtitle("Number of crimes in individual category")+
xlab("Number of crimes")+
ylab("Category of crime")
data_plot = data_plot[with(data_plot,order(-count)),]
Top_crimes = data_plot
print("Top 10 crimes")
top_10 = Top_crimes[1:10,1]
head(Top_crimes,20)
df = data.frame()
sum = 0
for (i in 1:dim(Top_crimes)[1]){
sum = sum + Top_crimes[i,2]
Top_crimes$CumCr[i] = sum/sum(Top_crimes$count)
}
per_20 = Top_crimes$CumCr[20]*100
print(paste("Percentage of crimes in top 20 categories = " ,
as.character(per_20)))
## Crime category by week, month and hour.
#Figures below show distribution of crime and change in type of crime since 2003.
F#rom the first plot, Larceny/theft is the most common type of crime.
#Further, there appears to be a skewness in the type of crimes.
#For example, there were 174900 incidents of LARCENY/THEFT where as only 6 of TREA since 2003.
#Crimes belonged to the top 10 categories 83% of the time.
#And top 20 categories had 97% of the crimes.
#Therefore, a classifier that classifies crime in top 20 categories may be sufficient for most crime categories.
#For now, I used a model where I was predicting probability for all 39 classes,
#but in future I will use fewer predictors to see if I can increase accuracy of the model for them.
#The second plot shows median total crimes per month from 2003 to 2015.
#Plot indicates that larceny/theft rates are on rise.
#Most interesting trend is reduction in number of vehicle thefts from 2006 to 2007.
# Types of crimes.
data_plot = data_train %>%
subset(Category %in% top_10) %>%
group_by(Years,Category,Month) %>%
summarise(count = n())
data_plot$Category = factor(data_plot$Category,levels = top_10)
ggplot(data = data_plot,aes(x=Years, y=count,fill = Category)) +
geom_boxplot() +
facet_wrap(~Category,ncol = 5)+
theme(legend.position="None",
axis.text.x = element_text(angle = 90, hjust = 1)) +
xlab("Year")+
ylab("Number of crime incidents")+
ggtitle("Variations in crime by year")+
xlab("Number of crimes")+
ylab("Year")
## Variation with hour, day of week and month
#Plots below show trends in crime for 3 main date factors,
#- Day of week: Crime rates change during the week. Crime incidents are higher on Friday, and lowest on Sundays
#- Month: Crime rate is highest during october, and lowest in december. Crime seems to follow a bimodal pattern with peaks in May and October and valleys in December and August.
#- Hour: Crime vs Hour of day shows a gruadual reduction in crime from midnight to 5 am, after which it rises from 5 am to 10 am, and remains at sustained high level until midnight.
#```{r echo=FALSE, message=FALSE, warning=FALSE}
# Crime vs DayOfWeek
months_name = c("Jan","Feb","Mar","Apr","May","Jun",
"Jul","Aug","Sep","Oct","Nov","Dec")
data_plot = data_train %>%
group_by(DayOfWeek,Years,Month,YearsMo) %>%
summarise(count = n())
p1 = ggplot(data = data_plot,aes(x=DayOfWeek, y=count,fill = DayOfWeek)) +
geom_boxplot() +
theme(legend.position="None") +
xlab("Day of week")+
ylab("Number of crime incidents")+
coord_cartesian(ylim = c(300,1200))
# Crime vs month
data_plot = data_train %>%
group_by(Month,Years,Month,YearsMo) %>%
summarise(count = n())
p2 = ggplot(data = data_plot,aes(x=as.numeric(Month), y=count,fill = Month)) +
geom_boxplot() +
xlab("Month")+
ylab("Number of crime incidents")+
theme(legend.position="None") +
scale_x_continuous(breaks = 1:12, labels=months_name)
# Crime vs hour of the day
data_plot = data_train %>%
group_by(Hour,Years,Month,YearsMo) %>%
summarise(count = n())
p3 = ggplot(data = data_plot,aes(x=Hour, y=count,fill = Hour)) +
geom_boxplot() +
xlab("Hour of day")+
ylab("Number of crime incidents")+
theme(legend.position="None")
grid.arrange(p1,p2,p3,ncol = 1,top="Important factors affecting crime rates")
#'''
## Seasonal patterns in crimes
#I also noticed seasonal patterns in data, where although the total crime counts were different, the normalized values followed similar trends.
#When normalized by mean and standard deviations seasonal patterns in month appear.
#'''{r echo=FALSE, message=FALSE, warning=FALSE}
months_name = c("Jan","Feb","Mar","Apr","May","Jun",
"Jul","Aug","Sep","Oct","Nov","Dec")
# Types of crime vs Month
top_10 = Top_crimes[1:10,1]
data_plot = data_train %>%
group_by(Category,Month) %>%
summarise(count = n()) %>%
mutate(norm_count = (count-mean(count))/sd(count))
p1 = ggplot(data = subset(data_plot, Category %in% top_10),
aes(x=as.numeric(Month), y=count,color = Category)) +
geom_line()+
geom_point()+
scale_x_discrete(breaks = 1:12, labels=c("Jan","Feb","Mar",
"Apr","May","Jun",
"Jul","Aug","Sep",
"Oct","Nov","Dec")) +
xlab("Months")+
ylab("Crime count") +
theme(legend.position="Bottom")
p2 = ggplot(data = subset(data_plot, Category %in% top_10),
aes(x=as.numeric(Month), y=norm_count,color = Category)) +
geom_line()+
geom_point()+
scale_x_discrete(breaks = 1:12, labels=c("Jan","Feb","Mar",
"Apr","May","Jun",
"Jul","Aug","Sep",
"Oct","Nov","Dec")) +
xlab("Months")+
ylab("Normalized crime count")+
theme(legend.position="None")
grid.arrange(p1,p2,ncol = 1,top = "Normalizing by month reveals common patterns in data")
#'''
#Similar patterns emerge in for hour also.
#Different lines represent crimes for different categories (Top 10 only).
#'''{r echo=FALSE}
# Crime rate vs day of week and Hour of day
top_10 = Top_crimes[1:10,1]
data_plot = data_train %>%
group_by(Category,Hour) %>%
summarise(count = n()) %>%
mutate(norm_count = (count-mean(count))/sd(count))
p1 = ggplot(data = subset(data_plot, Category %in% top_10),
aes(x=as.numeric(Hour), y=count,color = Category)) +
geom_line()+
geom_point() +
xlab("Hour of Day") +
ylab("Crime count") +
theme(legend.position="None")
p2 = ggplot(data = subset(data_plot, Category %in% top_10),
aes(x=as.numeric(Hour), y=norm_count,color = Category)) +
geom_line()+
geom_point() +
xlab("Hour of Day") +
ylab("Nomalized crime count") +
theme(legend.position="None")
grid.arrange(p1,p2,ncol = 1, top = "Normalized crime rate reveals seasonal pattern in hours")
#'''
#'''{r echo=FALSE, message=FALSE, warning=FALSE, training_factors}
## MAKING TRAINING FACTORS
make_training_factors = function(df) {
df$Years=paste("Yr",df$Years,sep = ".")
df$Years = factor(df$Years)
y <- as.data.frame(model.matrix(~df$Years - 1))
names(y) <- levels(df$Years)
df$Hour=paste("Hr",df$Hour,sep = ".")
df$Hour = factor(df$Hour)
h <- as.data.frame(model.matrix(~df$Hour - 1))
names(h) <- levels(df$Hour)
dow <- as.data.frame(model.matrix(~df$DayOfWeek - 1))
names(dow) <- levels(df$DayOfWeek)
df$Month=paste("Mon",df$Month,sep = ".")
df$Month = factor(df$Month)
m <- as.data.frame(model.matrix(~df$Month-1))
names(m) <- levels(df$Month)
head(m)
district <- as.data.frame(model.matrix(~df$PdDistrict - 1))
names(district) <- levels(df$PdDistrict)
df$pY=paste(df$PdDistrict,df$Years,sep = ".")
df$pY = factor(df$pY)
pY <- as.data.frame(model.matrix(~df$pY - 1))
names(pY) <- levels(df$pY)
#training set
train <- data.frame( y,dow, h, district, m,pY)
return(train)
}
MultiLogLoss <- function(act, pred)
{
eps = 1e-15;
nr <- nrow(pred)
pred = matrix(sapply( pred, function(x) max(eps,x)), nrow = nr)
pred = matrix(sapply( pred, function(x) min(1-eps,x)), nrow = nr)
ll = sum(act*log(pred) + (1-act)*log(1-pred))
ll = ll * -1/(nrow(act))
return(ll);
}
### TRAINING
#'''Data is fit with hour, day of week, month, year and police district as independent features.
#Below is the code to generate an output file submit for submission.
#This is work in progress, and I will test more complex algorithms later.
#This code got me in early 400s, with a log loss about 2.6.
#'''
#'''{r echo=TRUE, message=FALSE, warning=FALSE}
## TRAINING WITH DATA FROM 2012 ONLY.
set.seed(22)
## used this to generate sample and test set to test model
#        smp_size <- floor(0.5 * nrow(data_train)) # splitting data
#        train_ind <- sample(seq_len(nrow(data_train)), size = smp_size)
#        train <- data_train[train_ind, ]
#        test <- data_train[-train_ind, ]
train = data_train
target <- train$Category
#length(unique(target))
train = make_training_factors(train)
#dim(train)
#head(train)
gc()
#Build a linear model
model <- LiblineaR(train, target, type = 7, verbose = FALSE)
rm(train)
gc()
model
#Prepare test set.
test <- data_test
Id <- test$Id
test = make_training_factors(test)
head(test)
#Cleanup
gc()
#Build submission.
submit <- data.frame(predict(model,test, proba = TRUE)$probabilities[, levels(target)])
#```
#```{r echo=TRUE, message=FALSE, warning=FALSE}
#```
train <- read.csv("C:/Users/Pinank/Desktop/study/Spring 2016/CS 521 TCP IP Networking/Final Project")
View(train)
library (dplyr)
library(ggplot2)
library(data.table)
library(reshape2)
library(readr)
library(lubridate)
library(RgoogleMaps)
train<- filter(train,Category != "OTHER OFFENSES", Category != "NON-CRIMINAL", Category != "WARRANTS")
install.packages("dplyr")
install.packages("data.table")
install.packages("ggplot2")
install.packages("reshape2")
install.packages("readr")
install.packages("lubridate")
install.packages("RgoogleMaps")
train <- read.csv("C:/Users/Pinank/Desktop/study/Spring 2016/CS 521 TCP IP Networking/Final Project")
View(train)
library (dplyr)
library(ggplot2)
library(data.table)
library(reshape2)
library(readr)
library(lubridate)
library(RgoogleMaps)
train<- filter(train,Category != "OTHER OFFENSES", Category != "NON-CRIMINAL", Category != "WARRANTS")
install.packages("dplyr")
install.packages("data.table")
install.packages("ggplot2")
install.packages("reshape2")
install.packages("readr")
install.packages("RgoogleMaps")
install.packages("lubridate")
install.packages("readr")
install.packages("reshape2")
install.packages("lubridate")
install.packages("RgoogleMaps")
install.packages("lubridate")
install.packages("RgoogleMaps")
train <- read.csv("C:/Users/Pinank/Desktop/study/Spring 2016/CS 521 TCP IP Networking/Final Project")
train <- read.csv("C:/Users/Pinank/Desktop/study/Spring 2016/CS 521 TCP IP Networking/Final Project")
